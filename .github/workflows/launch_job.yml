name: Launch job

on:
  workflow_call:
    inputs:
      runs_on:
        required: false
        type: string
        default: magma-runner-set

      job_path:
        required: false
        type: string
        default: ''
      
      job_name:
        required: false
        type: string
        default: ''

      singularity:
          required: false
          type: string
          default: 'python-jupyter.sif'

      enable_tunnel:
        required: false
        type: boolean
        default: false

      enable_jupyter:
        required: false
        type: boolean
        default: true

      jupyter_singularity:
        required: false
        type: string
        default: 'python-jupyter.sif'

      enable_tgi:
        required: false
        type: boolean
        default: false

      tgi_singularity:
        required: false
        type: string
        default: 'text-generation-inference.singularity.1.4.4.sif'

      tgi_model:
        required: false
        type: string
        default: 'Mistral-7B-Instruct-v0.3'

      tgi_params:
        required: false
        type: string
        default: ''
      

jobs:
  launch-job:
    timeout-minutes: 43200
    runs-on: ${{ inputs.runs_on }}
    env:
      PORT1: "8888"
      PORT2: "8080"
      JOB_PATH: ${{ inputs.job_path }}
      JOB_NAME: ${{ inputs.job_name }}
      JOB_SINGULARITY_IMAGE: ${{ vars.GPFS_SINGULARITY_IMAGE_REGISTRY_PATH }}/${{ inputs.singularity }}
      JOB_ENABLE_TUNNEL: ${{ inputs.enable_tunnel }}
      JOB_ENABLE_JUPYTER: ${{ inputs.enable_jupyter }}
      GPFS_JUPYTER_SINGULARITY: ${{ vars.GPFS_SINGULARITY_IMAGE_REGISTRY_PATH }}/${{ inputs.jupyter_singularity }}
      JOB_TGI_ENABLE: ${{ inputs.enable_tgi }}
      GPFS_TGI_SINGULARITY: ${{ vars.GPFS_SINGULARITY_IMAGE_REGISTRY_PATH }}/${{ inputs.tgi_singularity }}
      GPFS_TGI_MODEL: ${{ inputs.tgi_model }}

    steps:
      - uses: langtech-bsc/magma/actions/set_secrets_to_env_action@main
        with:
          must_exist: 'REMOTE_HOST,REMOTE_USER,REMOTE_GROUP,SSH_PRIVATE_KEY'
          exclude: 'SSH_PRIVATE_KEY'
          json: ${{ toJson(secrets) }}
          name: 'secret'

      - uses: langtech-bsc/magma/actions/set_secrets_to_env_action@main
        with:
          must_exist: 'MLFLOW_TRACKING_SERVER_URL,GPFS_SINGULARITY_IMAGE_REGISTRY_PATH,GPFS_MODELS_REGISTRY_PATH'
          json: ${{ toJson(vars) }}
          name: 'secret'
   
      - name: Set extra variables to env
        run: |
          JOB_REPO_NAME=${GITHUB_REPOSITORY#$GITHUB_REPOSITORY_OWNER/}
          JOB_BRANCH=${GITHUB_HEAD_REF:-${GITHUB_REF#refs/heads/}}

          echo "JOB_REPO_NAME=${JOB_REPO_NAME}" >> "$GITHUB_ENV"
          echo "JOB_BRANCH=${JOB_BRANCH}" >> "$GITHUB_ENV"
          
          if [ '${{ env.JOB_ENABLE_JUPYTER }}' = 'true' ] || [ '${{ env.JOB_TGI_ENABLE }}' = 'true' ]; then
            echo "JOB_ENABLE_TUNNEL=true" >> "$GITHUB_ENV"
            echo "JOB_SLEEP=true" >> "$GITHUB_ENV"
          fi

          if [ -z "${{ env.JOB_NAME }}" ]; then 
            echo "JOB_NAME=${JOB_REPO_NAME}-${{ github.run_number }}" >> "$GITHUB_ENV"
          fi

          if [ -n "${{ inputs.tgi_params }}" ]; then
            echo 'JOB_TGI_PARAMS="${{ inputs.tgi_params }}"' >> "$GITHUB_ENV"
          fi

          if [ -z "${{ env.JOB_PATH }}" ]; then
            JOB_PATH="/gpfs/scratch/${{ secrets.REMOTE_GROUP }}/${{ secrets.REMOTE_USER }}/jobs/${JOB_REPO_NAME}/${{ github.run_number }}"
          fi

          echo "JOB_PATH=$JOB_PATH" >> "$GITHUB_ENV"
          echo "JOB_LOGS_PATH=$JOB_PATH/logs" >> "$GITHUB_ENV"
      
      - name: Log job variables (Job path, job name, etc)
        run: |
          echo "Job variables"
          echo "JOB_PATH: ${{env.JOB_PATH}}"
          echo "JOB_NAME: ${{env.JOB_NAME}}"
          echo "JOB_LOGS_PATH: ${{env.JOB_LOGS_PATH}}"
          echo "GPFS_SINGULARITY: ${{env.GPFS_SINGULARITY}}"
          echo "JOB_ENABLE_TUNNEL: ${{env.JOB_ENABLE_TUNNEL}}"
          echo "JOB_ENABLE_JUPYTER: ${{env.JOB_ENABLE_JUPYTER}}"
          echo "GPFS_JUPYTER_SINGULARITY: ${{env.GPFS_JUPYTER_SINGULARITY}}"
          echo "JOB_TGI_ENABLE: ${{env.JOB_TGI_ENABLE}}"
          echo "GPFS_TGI_SINGULARITY: ${{env.GPFS_TGI_SINGULARITY}}"
          echo "GPFS_TGI_MODEL: ${{env.GPFS_TGI_MODEL}}"
          echo "JOB_SLEEP: ${{env.JOB_SLEEP}}"

      - name: Set Socket variables
        if: ${{ env.JOB_ENABLE_TUNNEL == 'true' || env.JOB_ENABLE_TUNNEL == true}}
        run: |
          EXTRA_SOCKET=${{ env.JOB_PATH }}/socket${{ env.PORT2 }}.sock
          JUPYTER_SOCKET=${{ env.JOB_PATH }}/socket${{ env.PORT1 }}.sock
          echo "EXTRA_SOCKET=${EXTRA_SOCKET}" >> "$GITHUB_ENV"
          echo "JUPYTER_SOCKET=${JUPYTER_SOCKET}" >> "$GITHUB_ENV"

      - uses: actions/checkout@v4

      - name: Save job related env vars to file
        run: |
          mkdir -p src/logs
          env | grep -e '^JOB_' -e '^GPFS_' > src/job.env
          echo "JOB_SSH_TUNNEL_COMMAND=ssh -N -L ${{ env.PORT2 }}:${EXTRA_SOCKET} -L ${{ env.PORT1 }}:${JUPYTER_SOCKET} ${{ secrets.REMOTE_USER }}@${{ secrets.REMOTE_HOST }}" >> $GITHUB_ENV

      
      - uses: langtech-bsc/magma/actions/addons@main
        with:
          file: "src/launch.sh"
          jupyter: ${{ env.JOB_ENABLE_JUPYTER }}
          tgi: ${{ env.JOB_TGI_ENABLE }}
          sleep: ${{ env.JOB_SLEEP }}

      - name: Pre launch modifications
        run: |
          sed -i "s|\%JOB_NAME%|${{ env.JOB_NAME }}|" src/launch.sh
          sed -i "s|\%JOB_LOGS_PATH%|${{ env.JOB_LOGS_PATH  }}|" src/launch.sh
          sed -i "s|\%JOB_PATH%|${{ env.JOB_PATH  }}|" src/launch.sh

      # - name: Set up Python
      #   uses: actions/setup-python@v5
      #   with:
      #     python-version: '3.12'
      #     architecture: 'x64'

      - uses: webfactory/ssh-agent@v0.9.0
        with:
          ssh-private-key: ${{ secrets.SSH_PRIVATE_KEY }}

      # - name: Display Python version
      #   run: python -c "import sys; print(sys.version)"

      # - name: Install hpc rocket from source
      #   run: pip install hpc-rocket

      - name: Launch job
        run: |
          #Launching job...
          tempfile=$(mktemp)
          hpc-rocket launshellch rocket.yml 2>&1 | tee "$tempfile"
          output=$(cat "$tempfile")
          echo "SLURM_JOB_ID=$(echo "$output" | grep -oE 'job [0-9]+' | grep -oE '[0-9]+')" >> "$GITHUB_ENV"
      
      - name: Setup mlflow
        id: mlflow
        uses: langtech-bsc/magma/actions/mlflow@main
        with:
          experiment_name: ${GITHUB_REPOSITORY#$GITHUB_REPOSITORY_OWNER/}
          remote_host: ${{ secrets.REMOTE_HOST }}
          remote_user: ${{ secrets.REMOTE_USER }}
          remote_source_path: ${{ env.JOB_LOGS_PATH }}
          traking_url: ${{ env.MLFLOW_TRACKING_SERVER_URL }}
          run_name: ${{ env.SLURM_JOB_ID }} 
          schedule: 'true'
        continue-on-error: true
      
      - name: Monitoring and status (CHECK THE LOGS HERE)
        run: |
          if [ -z "${{ steps.mlflow.outputs.artifact_url }}" ]; then
            echo "Mlflow API is not available, please contact MLOps team or try running the workflow again"
            echo "If you are running the workflow locally with act, ensure you have BSC VPN connected"
            hpc-rocket cancel rocket.yml --jobid ${{ env.SLURM_JOB_ID }}
            echo "Job canceled: ${{ env.SLURM_JOB_ID }}"
            exit 1
          else
            echo "Check the logs at: ${{ steps.mlflow.outputs.artifact_url }}"
            echo "Keep in mind that synchronization may take a little bit"
          fi

      - name: Watch job
        id: watch
        run: | 
         #Live status
         echo "Check the logs at: ${{ steps.mlflow.outputs.artifact_url }}"
         echo "Keep in mind that synchronization may take a little bit"
         nohup $(while true; do
            # hpc-rocket status rocket.yml --jobid ${{ env.SLURM_JOB_ID }} 
            running=$(hpc-rocket status rocket.yml --jobid ${{ env.SLURM_JOB_ID }}  | grep "RUNNING" | wc -l)
            if [[ $running > 0 ]]
            then
              nohup ml_flow -t sync > ${{ steps.mlflow.outputs.sync_dir }}/mlflow.log 2>&1 < /dev/null &
              echo "mlflow_pid=$!" >> $GITHUB_OUTPUT
              if [ '${{ env.JOB_ENABLE_TUNNEL }}' = 'true' ]; then
                SLURM_JOB_NODE=$(ssh -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null ${{ secrets.REMOTE_USER }}@${{ secrets.REMOTE_HOST }} "squeue -j ${{ env.SLURM_JOB_ID }}  -o '%R'" | tail -1)
                
                if [[ $SLURM_JOB_NODE == *"["* ]]; then    
                    IFS='[' read -r prefix range <<< "$SLURM_JOB_NODE"  # Split by '['
                    if [[ $range == *"-"* ]]; then                      # Handle range (contains '-')
                        IFS='-' read -r start end <<< "$range"
                    elif [[ $range == *","* ]]; then                    # Handle list (contains ',')
                        IFS=',' read -r start rest <<< "$range"
                    else
                        start=$range
                    fi
                    
                    start=${start%]*}                                   # Remove ']' from the start variable
                    result="${prefix}${start}"                          # Join prefix with start
                    SLURM_JOB_NODE=$result
                fi

                ssh -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null ${{ secrets.REMOTE_USER }}@${{ secrets.REMOTE_HOST }} "rm -rf ${{ env.EXTRA_SOCKET }} ${{ env.JUPYTER_SOCKET }}; ssh -Nf -L ${{ env.EXTRA_SOCKET }}:localhost:${{ env.PORT2 }} -L ${{ env.JUPYTER_SOCKET }}:localhost:${{ env.PORT1 }} ${SLURM_JOB_NODE} && chmod 660 -f ${{ env.EXTRA_SOCKET }} ${{ env.JUPYTER_SOCKET }} 123abc "
                echo "${{ env.JOB_SSH_TUNNEL_COMMAND }}" > ${{ steps.mlflow.outputs.sync_dir }}/tunnel.log
              fi
              break
            fi
            sleep 5
          done)  > ./tmp 2>&1 < /dev/null &

          (while true; do
            hpc-rocket status rocket.yml --jobid ${{ env.SLURM_JOB_ID }} 
            sleep 20
          done) &
         hpc-rocket watch rocket.yml --jobid ${{ env.SLURM_JOB_ID }} 
        shell: bash
        continue-on-error: true

      - name: Kill mlflow
        if: always()
        run: | 
          kill -9 ${{ steps.watch.outputs.mlflow_pid }}
        continue-on-error: true

      - name: Check on success
        if: steps.watch.outcome == 'success'
        run: | 
          ml_flow -t stop
          exit 0

      - name: Check on failures
        if: steps.watch.outcome != 'success'
        run: | 
          ml_flow -t stop --failed
          exit 1
