name: Launch job

on:
  workflow_call:
    inputs:
      runs_on:
        required: false
        type: string
        default: magma-runner-set

      job_path:
        required: false
        type: string
        default: ''
      
      job_name:
        required: false
        type: string
        default: ''

      singularity:
          required: false
          type: string
          default: 'python-jupyter.sif'

      enable_tunnel:
        required: false
        type: boolean
        default: false

      jupyter_enable:
        required: false
        type: boolean
        default: true

      jupyter_singularity:
        required: false
        type: string
        default: 'python-jupyter.sif'

      tgi_enable:
        required: false
        type: boolean
        default: false

      tgi_singularity:
        required: false
        type: string
        default: 'text-generation-inference.singularity.1.4.4.sif'

      tgi_model:
        required: false
        type: string
        default: 'Mixtral-8x7B-Instruct-v0.1'

      

jobs:
  launch-job:
    timeout-minutes: 43200
    runs-on: ${{ inputs.runs_on }}
    env:
      PORT1: "8888"
      PORT2: "8080"
      JOB_PATH: ${{ inputs.job_path }}
      JOB_NAME: ${{ inputs.job_name }}
      JOB_SINGULARITY: ${{ inputs.singularity }}
      JOB_ENABLE_TUNNEL: ${{ inputs.enable_tunnel }}
      JOB_JUPTER_ENABLE: ${{ inputs.jupyter_enable }}
      JOB_JUPITER_SINGULARITY: ${{ inputs.jupyter_singularity }}
      JOB_TGI_ENABLE: ${{ inputs.tgi_enable }}
      JOB_TGI_SINGULARITY: ${{ inputs.tgi_singularity }}
      JOB_TGI_MODEL: ${{ inputs.tgi_model }}

    steps:
      - uses: langtech-bsc/magma/actions/set_secrets_to_env_action@main
        with:
          must_exist: 'REMOTE_HOST,REMOTE_USER,REMOTE_GROUP,SSH_PRIVATE_KEY'
          exclude: 'SSH_PRIVATE_KEY'
          json: ${{ toJson(secrets) }}
          name: 'secret'

      - uses: langtech-bsc/magma/actions/set_secrets_to_env_action@main
        with:
          must_exist: 'MLFLOW_TRACKING_SERVER_URL,GPFS_SINGULARITY_IMAGE_REGISTRY_PATH'
          json: ${{ toJson(vars) }}
          name: 'secret'
   
      - name: Set extra variables to env
        run: |
          JOB_REPO_NAME=${GITHUB_REPOSITORY#$GITHUB_REPOSITORY_OWNER/}
          JOB_BRANCH=${GITHUB_HEAD_REF:-${GITHUB_REF#refs/heads/}}

          echo "JOB_REPO_NAME=${JOB_REPO_NAME}" >> $GITHUB_ENV
          echo "JOB_BRANCH=${JOB_BRANCH}" >> $GITHUB_ENV
          
          if [ '${{ env.JOB_JUPTER_ENABLE }}' = 'true' ] || [ '${{ env.JOB_TGI_ENABLE }}' = 'true' ]; then
            echo "JOB_ENABLE_TUNNEL=true" >> $GITHUB_ENV
            echo "JOB_SLEEP=true" >> $GITHUB_ENV
          fi

          if [ -z "${{ env.JOB_NAME }}" ]; then 
            echo "JOB_NAME=${JOB_REPO_NAME}-${{ github.run_number }}" >> $GITHUB_ENV
          fi

          if [ -z "${{ env.JOB_PATH }}" ]; then
            JOB_PATH="/gpfs/scratch/${{ secrets.REMOTE_GROUP }}/${{ secrets.REMOTE_USER }}/jobs/${JOB_REPO_NAME}/${{ github.run_number }}"
          fi

          echo "JOB_PATH=$JOB_PATH" >> $GITHUB_ENV
          echo "JOB_LOGS_PATH=$JOB_PATH/logs" >> $GITHUB_ENV
      
      - name: Log job variables
        run: |
          echo "Job variables"
          echo "JOB_PATH: ${{env.JOB_PATH}}"
          echo "JOB_NAME: ${{env.JOB_NAME}}"
          echo "JOB_LOGS_PATH: ${{env.JOB_LOGS_PATH}}"
          echo "JOB_SINGULARITY: ${{env.JOB_SINGULARITY}}"
          echo "JOB_ENABLE_TUNNEL: ${{env.JOB_ENABLE_TUNNEL}}"
          echo "JOB_JUPTER_ENABLE: ${{env.JOB_JUPTER_ENABLE}}"
          echo "JOB_JUPITER_SINGULARITY: ${{env.JOB_JUPITER_SINGULARITY}}"
          echo "JOB_TGI_ENABLE: ${{env.JOB_TGI_ENABLE}}"
          echo "JOB_TGI_SINGULARITY: ${{env.JOB_TGI_SINGULARITY}}"
          echo "JOB_TGI_MODEL: ${{env.JOB_TGI_MODEL}}"
        

      - name: Set Socket variables
        if: ${{ env.JOB_ENABLE_TUNNEL == 'true' }}
        run: |
          export EXTRA_SOCKET=${{ env.JOB_PATH }}/socket${{ env.PORT2 }}.sock
          export JUPYTER_SOCKET=${{ env.JOB_PATH }}/socket${{ env.PORT1 }}.sock
          echo "EXTRA_SOCKET=${EXTRA_SOCKET}" >> $GITHUB_ENV
          echo "JUPYTER_SOCKET=${JUPYTER_SOCKET}" >> $GITHUB_ENV

          echo "JOB_SSH_TUNNEL_COMMAND=ssh -N -L ${{ env.PORT2 }}:${EXTRA_SOCKET} -L ${{ env.PORT1 }}:${JUPYTER_SOCKET} ${{ secrets.REMOTE_USER }}@${{ secrets.REMOTE_HOST }}" >> $GITHUB_ENV

      - uses: actions/checkout@v4

      - name: Save job related env vars to file
        run: |
          env | grep -e '^JOB_' -e '^GPFS_' > src/job.env
      
      - uses: langtech-bsc/magma/actions/addons@main
        with:
          file: "src/launch.sh"
          jupyter: ${{ env.JOB_JUPTER_ENABLE }}
          tgi: ${{ env.JOB_TGI_ENABLE }}
          sleep: ${{ env.JOB_SLEEP }}

      - name: Pre launch modifications
        run: |
          sed -i "s|\%JOB_NAME%|${{ env.JOB_NAME }}|" src/launch.sh
          sed -i "s|\%JOB_PATH%|${{ env.JOB_PATH  }}|" src/launch.sh

      # - name: Set up Python
      #   uses: actions/setup-python@v5
      #   with:
      #     python-version: '3.12'
      #     architecture: 'x64'

      - uses: webfactory/ssh-agent@v0.9.0
        with:
          ssh-private-key: ${{ secrets.SSH_PRIVATE_KEY }}

      # - name: Display Python version
      #   run: python -c "import sys; print(sys.version)"

      # - name: Install hpc rocket from source
      #   run: pip install hpc-rocket

      - name: Launch job
        run: |
          #Launching job...
          tempfile=$(mktemp)
          hpc-rocket launch rocket.yml 2>&1 | tee "$tempfile"
          output=$(cat "$tempfile")
          echo "SLURM_JOB_ID=$(echo "$output" | grep -oE 'job [0-9]+' | grep -oE '[0-9]+')" >> $GITHUB_ENV
      
      - name: Setup mlflow
        id: mlflow
        uses: langtech-bsc/magma/actions/mlflow@main
        with:
          experiment_name: ${GITHUB_REPOSITORY#$GITHUB_REPOSITORY_OWNER/}
          remote_host: ${{ secrets.REMOTE_HOST }}
          remote_user: ${{ secrets.REMOTE_USER }}
          remote_source_path: ${{ env.JOB_PATH }}/logs
          traking_url: ${{ env.MLFLOW_TRACKING_SERVER_URL }}
          run_name: ${{ env.SLURM_JOB_ID }} 
          schedule: 'true'
      
      - name: Monitoring and status (CHECK THE LOGS HERE)
        run: |
          if [ -z "${{ steps.mlflow.outputs.artifact_url }}" ]; then
            echo "Mlflow API is not available, please contact MLOps team or try running the workflow again"
            echo "If you are running the workflow locally with act, ensure you have BSC VPN connected"
            exit 1
          else
            echo "Check the logs at: ${{ steps.mlflow.outputs.artifact_url }}"
            echo "Keep in mind that synchronization may take a little bit"
          fi

      - name: Watch job
        id: watch
        run: | 
         #Live status
         echo "Check the logs at: ${{ steps.mlflow.outputs.artifact_url }}"
         echo "Keep in mind that synchronization may take a little bit"
         nohup $(while true; do
            # hpc-rocket status rocket.yml --jobid ${{ env.SLURM_JOB_ID }} 
            running=$(hpc-rocket status rocket.yml --jobid ${{ env.SLURM_JOB_ID }}  | grep "RUNNING" | wc -l)
            if [[ $running > 0 ]]
            then
              nohup ml_flow -t sync > ${{ steps.mlflow.outputs.sync_dir }}/mlflow.log 2>&1 < /dev/null &
              echo "mlflow_pid=$!" >> $GITHUB_OUTPUT
              if [ '${{ env.JOB_ENABLE_TUNNEL }}' = 'true' ]; then
                SLURM_JOB_NODE=$(ssh -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null ${{ secrets.REMOTE_USER }}@${{ secrets.REMOTE_HOST }} "squeue -j ${{ env.SLURM_JOB_ID }}  -o '%R'" | tail -1)
                
                if [[ $SLURM_JOB_NODE == *"["* ]]; then    
                    IFS='[' read -r prefix range <<< "$SLURM_JOB_NODE"  # Split by '['
                    if [[ $range == *"-"* ]]; then                      # Handle range (contains '-')
                        IFS='-' read -r start end <<< "$range"
                    elif [[ $range == *","* ]]; then                    # Handle list (contains ',')
                        IFS=',' read -r start rest <<< "$range"
                    else
                        start=$range
                    fi
                    
                    start=${start%]*}                                   # Remove ']' from the start variable
                    result="${prefix}${start}"                          # Join prefix with start
                    SLURM_JOB_NODE=$result
                fi

                ssh -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null ${{ secrets.REMOTE_USER }}@${{ secrets.REMOTE_HOST }} "rm -rf ${{ env.EXTRA_SOCKET }} ${{ env.JUPYTER_SOCKET }}; ssh -Nf -L ${{ env.EXTRA_SOCKET }}:localhost:${{ env.PORT2 }} -L ${{ env.JUPYTER_SOCKET }}:localhost:${{ env.PORT1 }} ${SLURM_JOB_NODE} && chmod 660 -f ${{ env.EXTRA_SOCKET }} ${{ env.JUPYTER_SOCKET }} 123abc "
                echo "${{ env.JOB_SSH_TUNNEL_COMMAND }}" > ${{ steps.mlflow.outputs.sync_dir }}/tunnel.log
              fi
              break
            fi
            sleep 5
          done)  > ./tmp 2>&1 < /dev/null &

          (while true; do
            hpc-rocket status rocket.yml --jobid ${{ env.SLURM_JOB_ID }} 
            sleep 20
          done) &
         hpc-rocket watch rocket.yml --jobid ${{ env.SLURM_JOB_ID }} 
        shell: bash
        continue-on-error: true

      - name: Kill mlflow
        if: always()
        run: | 
          kill -9 ${{ steps.watch.outputs.mlflow_pid }}
        continue-on-error: true

      - name: Check on success
        if: steps.watch.outcome == 'success'
        run: | 
          ml_flow -t stop
          exit 0

      - name: Check on failures
        if: steps.watch.outcome != 'success'
        run: | 
          ml_flow -t stop --failed
          exit 1
